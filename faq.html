<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>
  <meta content="text/html; charset=ISO-8859-1" http-equiv="content-type" />
  <title>FAQ - Modern GPU</title>
  <link href="mgpu.css" rel="stylesheet" type="text/css" />
  <script src="syntaxhighlighter_3.0.83/scripts/shCore.js" type="text/javascript"></script>
  <script src="syntaxhighlighter_3.0.83/scripts/shBrushCpp.js" type="text/javascript"></script>
  <link href="syntaxhighlighter_3.0.83/styles/shThemeDefault.css" rel="stylesheet" type="text/css" />
  <link href="syntaxhighlighter_3.0.83/styles/shCore.css" rel="stylesheet" type="text/css" />
  <script type="text/javascript"> SyntaxHighlighter.all() </script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-25772750-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head><body class="tutorial"><a href="https://github.com/NVlabs/moderngpu"><img style="position: absolute; top: 0; right: 0; border: 0;" width="149" height="149" src="forkme_right_green_007200.png" alt="Fork me on GitHub" /></a>
<div class="copyright">
<p><strong>&copy; 2013, NVIDIA CORPORATION. All rights reserved.</strong></p>
<p>Code and text by <a href="https://twitter.com/moderngpu">Sean Baxter</a>, NVIDIA Research.</p>

<p>(Click <a href="faq.html#license">here</a> for license. Click <a href="faq.html#contact">here</a> for contact information.)</p>
</div><br />

<div class="toclist"><ul>
 	<li class="tocprev">&nbsp;</li>
	<li class="tocmiddle"><a href="index.html">Contents</a></li>
    <li class="tocnext"><a href="intro.html">Introduction</a> &raquo;</li></ul>
</div><br/>
<h1>FAQ</h1>
<h2><a id="downloading">Downloading</a></h2>
<p>You can download a snapshot of the repository <a href="https://github.com/NVlabs/moderngpu/archive/master.zip">here</a>. </p>
<div class="figure"><img src="download.png" width="235" height="174" alt=" " /></div>
<p>Users may find more flexibility if they <em>fork</em> this repository. At 
  <a href="https://github.com/NVlabs/moderngpu">https://github.com/NVlabs/moderngpu</a>, click on the Fork button in the upper-right. This creates a copy of the repository in your own github account.</p>
<div class="snip"><pre>git clone git@github.com:yourname/moderngpu</pre></div>
<p>From the command line you can clone your own fork of the project onto your local machine. You can make changes to the project and these will be updated in your own repository. Users forking MGPU are treated to Github's excellent suite of development tools. Use the <a href="https://github.com/blog/39-say-hello-to-the-network-graph-visualizer">Network Graph Visualizer</a> to stay current with Modern GPU updates.</p>
<h2><a id="compiling">Compiling</a></h2>
<p>The Modern GPU library is entirely defined in headers under the include directory, except for one .cu and one .cpp 
files that must be compiled and linked manually: <a href="https://github.com/moderngpu/moderngpu/blob/V1.1/src/mgpucontext.cu">src/mgpucontext.cu</a> and <a href="https://github.com/moderngpu/moderngpu/blob/V1.1/src/mgpuutil.cpp">src/mgpuutil.cpp</a>. This library has not been tested on sm_1x targets, which use a different compiler stack; therefore targeting these architectures has been disabled in the headers. </p>
<p>All device and host functions are included from <a href="https://github.com/moderngpu/moderngpu/blob/V1.1/include/moderngpu.cuh">include/moderngpu.cuh</a>; this is all you need to include to access everything. Additionally, all functions and types are defined inside the <code>mgpu</code> namespace.</p>
<p>To compile from the command line (from the <a href="https://github.com/NVlabs/moderngpu/tree/master/tests">moderngpu/demo</a> directory):</p>
<div class="snip">
  <pre>nvcc -arch=sm_20 -I ../include/ -o demo ../src/mgpucontext.cu ../src/mgpuutil.cpp demo.cu</pre></div>
<p>To specifically target multiple device architectures (necessary if you are using LaunchBox to tune kernels), try something like this:</p>
<div class="snip">
  <pre>nvcc -gencode=arch=compute_20,code=\"sm_20,compute_20\" ^
    -gencode=arch=compute_35,code=\"sm_35,compute_35\" -I ../include -o demo ^
    ../src/mgpucontext.cu ../src/mgpuutil.cpp demo.cu</pre></div>
<p>Developers on Linux can modify one of the provided GNU Make files.</p>
<p>If you are a Visual Studio user, MGPU includes a solution for VS2010 with projects for the demo and each benchmark. To start a new project that uses CUDA and MGPU, create a new &quot;Win32 Project&quot; or &quot;Win32 Console Project.&quot; Right-click on the project in the Solution Explorer and choose &quot;Build Customizations...&quot; This lists configuration files for each CUDA Toolkit installed on your system. Check the newest one:</p>
<div class="figure"><img src="msvccustomization.png" width="602" height="358" alt=" " /></div>
<p>Right-click on the project again, select &quot;Add-&gt;Existing Items...&quot; and add format.cpp, random.cpp, and mgpucontext.cpp from the src directory of your Modern GPU directory.</p>
<p>Optional: If you want to use the same project settings as MGPU, in the menu bar select &quot;View-&gt;Property Manager.&quot; Right click on your project in the Property Manager and choose &quot;Add Existing Property Sheet...&quot; Select vs.props from the base directory of your MGPU install.</p>
<p>To configure CUDA properties for the project, go back to the Solution Explorer, right click on the project, and choose &quot;Properties.&quot;</p>
<div class="figure"><img src="msvcproperties.png" width="733" height="308" alt=" " /></div>
<p>Make sure to compile  with compute_20,sm_20 and higher; compute_1x will not build. You'll need to set mgpu/include under &quot;Additional Include Directories&quot; in the C/C++-&gt;General property page. Additionally you'll need to link against cudart.lib in Linker-&gt;Input-&gt;Additional Dependencies.</p>
<h2><a id="debugging">Debugging</a></h2>
<p>NVIDIA has offers Nsight, a rather impressive development and debugging suite for <a href="https://developer.nvidia.com/nvidia-nsight-visual-studio-edition">Visual Studio</a> and <a href="https://developer.nvidia.com/nsight-eclipse-edition">Eclipse</a>. I'm a bit of a luddite and mostly get by with two simple tools:</p>
<h3>cuda-memcheck</h3>
<p><a href="https://developer.nvidia.com/cuda-memcheck">cuda-memcheck</a> is a post-mortem debugger for the command line. When your kernel makes an out-of-range load/store or something else forbidden, cuda-memcheck 
aborts the program and prints detailed information on the nature of the error.</p>
<div class="snip">
  <pre class="brush: cpp; toolbar: false">#include &lt;cuda.h>

__global__ void Foo(int* data_global) {
	__shared__ int s[128];

	int tid = threadIdx.x;
	s[tid + 1] = tid;			// out-of-range store!
	__syncthreads();

	data_global[tid] = s[tid];
}

int main(int argc, char** argv) {
	int* data;
	cudaMalloc((void**)&amp;data, 128 * sizeof(int));
	Foo&lt;&lt;&lt;1, 128>>>(data);

	cudaDeviceSynchronize();
	return 0;
}</pre><hr />
<pre>cuda-memcheck tests.exe
========= CUDA-MEMCHECK
========= Invalid __shared__ write of size 4
=========     at 0x00000020 in c:/projects/mgpulib/tests/test.cu:7:Foo(int*)
=========     by thread (127,0,0) in block (0,0,0)
=========     Address 0x00000200 is out of bounds
=========     Saved host backtrace up to driver entry point at kernel launch time
=========     Host Frame:C:\Windows\system32\nvcuda.dll (cuLaunchKernel + 0x166) [0xc196]</pre></div>
<p>cuda-memcheck reports the nature of the error (invalid __shared__ write of size 4) and the function it occurred in. If you compile with -lineinfo (or select the appropriate box in the Visual Studio CUDA C/C++ properties), cuda-memcheck might even give you the line number, as it did in this case.</p>
<p>If you want more context, use cuobjdump to dump the disassembly of your kernel:</p>
<div class="snip">
  <pre>cuobjdump -sass tests.exe

Fatbin elf code:
================
arch = sm_20
code version = [1,6]
producer = cuda
host = windows
compile_size = 32bit
identifier = c:/projects/mgpulib/tests/test.cu

        code for sm_20
                Function : _Z3FooPi
        /*0000*/     /*0x00005de428004404*/     MOV R1, c [0x1] [0x100];
        /*0008*/     /*0x84001c042c000000*/     S2R R0, SR_Tid_X;
        /*0010*/     /*0xfc1fdc03207e0000*/     IMAD.U32.U32 RZ, R1, RZ, RZ;
        /*0018*/     /*0x08009c036000c000*/     SHL R2, R0, 0x2;
        /*0020*/     /*0x10201c85c9000000*/     STS [R2+0x4], R0;
        /*0028*/     /*0xffffdc0450ee0000*/     BAR.RED.POPC RZ, RZ;
        /*0030*/     /*0x00201c85c1000000*/     LDS R0, [R2];
        /*0038*/     /*0x80209c0348004000*/     IADD R2, R2, c [0x0] [0x20];
        /*0040*/     /*0x00201c8590000000*/     ST [R2], R0;
        /*0048*/     /*0x00001de780000000*/     EXIT;
                .........................</pre></div>
<p>cuda-memcheck reported an &quot;invalid __shared__ write of size 4&quot; at address 0x00000020. The disassembly shows us the instruction at this address, and it is indeed an STS (store to shared 4 bytes).</p>
<h3>printf</h3>
<p>Device-side printf is available on architectures sm_20 and later. It is extremely helpful. However you don't want 100,000 threads all printing to the console at once. Try to narrow down your problem to a single offending CTA and print from that. Individual printf statements are treated atomically (the entire string will come out at once), however the order in which threads print is undefined. It is helpful practice to store arguments to shared memory, synchronize, and have thread 0 read 
out the elements in order and printf in a loop.</p>
<p>The results of a device printf are not displayed until the next synchronizing runtime call after the kernel launch. This could be a <code>cudaDeviceSynchronize</code>, <code>cudaMalloc</code>, or <code>cudaMemcpy</code>.</p>
<p>Although printf is among the most primitive of debugging tools, it is surprisingly effective with data-parallel languages. Active debugging is often too fine-grained to understand the activity across an entire CTA.</p>
<h2><a id="gettingstarted">Getting started</a></h2>
<p><em><strong>How do I get started with CUDA?</strong></em></p>
<p>The best place to get started with CUDA is the official <a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">Programming Guide</a>. This is an up-to-date, 
correct, and concise overview of all of the device's capabilities and the APIs needed to use them.</p>
<p>There is a growing library of textbooks that paint a more detailed picture of GPU computing:</p>
<ul class="idiom">
	<li>
  <p><a href="http://www.amazon.com/CUDA-Handbook-Comprehensive-Guide-Programming/dp/0321809467">The CUDA Handbook</a> - Nicholas Wilt</p></li>
	<li>
  <p><a href="http://www.amazon.com/CUDA-Programming-Developers-Computing-Applications/dp/0124159338">CUDA Programming</a> - Shane Cook</p></li>

	<li>
  <p><a href="http://www.amazon.com/CUDA-Application-Design-Development-Farber/dp/0123884268">CUDA Application Design and Development</a> - Rob Farber</p></li>
	<li><p><a href="http://www.amazon.com/CUDA-Example-Introduction-General-Purpose-Programming/dp/0131387685">CUDA by Example</a> - Jason Sanders</p></li>
	<li>
  <p><a href="http://www.amazon.com/Programming-Massively-Parallel-Processors-Edition/dp/0124159923">Programming Massively Parallel Processors</a> - David Kirk and Wen-mei Hwu</p></li>
</ul>	
<p>Professor <a href="https://twitter.com/jowens">John Owens</a> of UC Davis and  Professor <a href="https://twitter.com/davedotluebke">David Luebke</a>, Graphics Research chief at NVIDIA, produced a video-rich <a href="https://www.udacity.com/course/cs344">CUDA course</a>, available for free at Udacity, that covers hardware architecture, the CUDA toolkit, and parallel algorithms.</p>
<p>The <a href="https://devtalk.nvidia.com/">CUDA Forums</a> are the most trafficked pages for giving and receiving help. <a href="http://www.stackoverflow.com/questions/tagged/cuda">Stackoverflow</a> also is very popular.</p>
<h2><a id="contact">Contact</a></h2>
<p>To contact me on email, use moderngpu@gmail.com.</p>
<p>Follow <a href="https://twitter.com/moderngpu">@moderngpu</a> for notifications of new content.</p>
<p>I can often be found in #cuda on <a href="http://freenode.net/">Freenode IRC</a>.</p>
<h2><a id="license">License</a></h2>
<p>The new Modern GPU library is provided under the <a href="http://opensource.org/licenses/BSD-3-Clause">3-clause BSD license</a>:</p>
<div class="snip"><pre>/******************************************************************************
 * Copyright (c) 2013, NVIDIA CORPORATION.  All rights reserved.
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *     * Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *     * Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *     * Neither the name of the NVIDIA CORPORATION nor the
 *       names of its contributors may be used to endorse or promote products
 *       derived from this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" 
 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE 
 * ARE DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY
 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 ******************************************************************************/</pre></div>
<br />
<div class="toclist"><ul>
 	<li class="tocprev">&nbsp;</li>
	<li class="tocmiddle"><a href="index.html">Contents</a></li>
    <li class="tocnext"><a href="intro.html">Introduction</a> &raquo;</li></ul>
</div><br/>

</body></html>